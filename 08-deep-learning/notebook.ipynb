{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN194dYuBqnnkkZm0GYq9xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sargent-mg/ml-zoomcamp/blob/main/08-deep-learning/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset:"
      ],
      "metadata": {
        "id": "L4J-2NwECv7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNDyJlTdABiD",
        "outputId": "35f1c822-a81a-4078-bae4-71ba8a43020b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clothing-dataset-small'...\n",
            "remote: Enumerating objects: 3839, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (400/400), done.\u001b[K\n",
            "remote: Total 3839 (delta 9), reused 385 (delta 0), pack-reused 3439 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3839/3839), 100.58 MiB | 25.65 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Updating files: 100% (3783/3783), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains:\n",
        "- 10 clothing categories (dress, hat, longsleeve, outwear, pants, shirt, shoes, shorts, skirt, t-shirt)\n",
        "- Training, validation, and test splits\n",
        "- Pre-organized directory structure"
      ],
      "metadata": {
        "id": "RCTX4-UnCxnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction to PyTorch\n",
        "\n",
        "PyTorch is a popular open-source deep learning framework developed by Facebook's AI Research lab. It provides:\n",
        "- Dynamic computation graphs (define-by-run)\n",
        "- Pythonic API\n",
        "- Strong GPU acceleration\n",
        "- Rich ecosystem of tools and libraries\n",
        "\n",
        "Key Differences from TensorFlow/Keras:\n",
        "\n",
        "| TensorFlow/Keras | PyTorch |\n",
        "|------------------|---------|\n",
        "| `model.fit()` | Manual training loop |\n",
        "| `ImageDataGenerator` | `Dataset` + `DataLoader` + `transforms` |\n",
        "| `keras.layers.Dense()` | `nn.Linear()` |\n",
        "| `keras.Model` | `nn.Module` |\n",
        "| `.h5` or `.keras` files | `.pth` or `.pt` files |"
      ],
      "metadata": {
        "id": "KD8EL6g6Cz_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_FpKKBLLBHwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PyTorch and Image Loading\n",
        "\n",
        "PyTorch is a popular open-source deep learning framework developed by Facebook's AI Research lab.\n",
        "\n",
        "Key differences from TensorFlow/Keras:\n",
        "- Dynamic computation graphs (define-by-run)\n",
        "- More Pythonic and flexible\n",
        "- Manual training loops instead of `model.fit()`\n",
        "- Explicit device management (CPU/GPU)\n",
        "\n",
        "### Loading and Preprocessing Images\n",
        "\n",
        "Images are represented as 3D arrays:\n",
        "- Height × Width × Channels\n",
        "- Channels: RGB (Red, Green, Blue)\n",
        "- Each channel: 8 bits (0-255 values)"
      ],
      "metadata": {
        "id": "GbjRfbAfCqhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load an image.\n",
        "img = Image.open('clothing-dataset-small/train/pants/0098b991-e36e-4ef1-b5ee-4154b21e2a92.jpg')\n",
        "\n",
        "# Resize to target size\n",
        "img = img.resize((224, 224))\n",
        "\n",
        "# Convert to numpy array\n",
        "x = np.array(img)\n",
        "print(x.shape)  # (224, 224, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baw0wkRUBLOO",
        "outputId": "978f5d3f-a1b8-4961-91ac-52f1bf2b92ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "DIPHTBG4B_4_",
        "outputId": "9227ba84-c311-4f73-976a-4e951d6902d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Pre-trained Models\n",
        "\n",
        "Instead of training from scratch, we'll use a model pre-trained on ImageNet (1.4M images, 1000 classes).\n",
        "\n",
        "Why use pre-trained models?\n",
        "\n",
        "- Already learned to recognize edges, textures, shapes\n",
        "- Saves training time\n",
        "- Works well even with small datasets\n",
        "- Better performance than training from scratch\n",
        "\n",
        "### Using MobileNetV2\n",
        "\n",
        "We'll use MobileNetV2 (in the original tutorial we used Xception):"
      ],
      "metadata": {
        "id": "jI18CEBbCIWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "PG-O7EjEDeQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model\n",
        "model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K4Qxy7JDMQH",
        "outputId": "35c50faf-451b-4f54-d5d5-fca48e6512ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 152MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing for MobileNetV2\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "MOtE26gSDiTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = preprocess(img)"
      ],
      "metadata": {
        "id": "HPlzEAQbDjbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_t = torch.unsqueeze(x, 0)"
      ],
      "metadata": {
        "id": "FtoGPb9LEcs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thMMdvraEixk",
        "outputId": "c7a869f0-d6cd-4407-a6f5-6a6a4fc12d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gImsW8qqEjkS",
        "outputId": "1da33a75-e94b-4af6-9f78-9c0ef42a90ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll make a prediction.\n",
        "with torch.no_grad():\n",
        "    output = model(batch_t)"
      ],
      "metadata": {
        "id": "q8r7PhvKEx_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTM9JWqhE9ft",
        "outputId": "405af1a5-bd70-4906-b1c5-0eb050814a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, indices = torch.sort(output, descending=True)\n",
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8MFvAOmFEu9",
        "outputId": "4c128228-9962-40c1-9982-477113c82004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[608, 834, 841, 474, 689, 824, 869, 906, 501, 885, 601, 457, 911, 735,\n",
              "         655, 775, 697, 431, 610, 842, 568, 411, 617, 452, 678, 516, 797, 796,\n",
              "         414, 578, 399, 434, 570, 630, 523, 591, 636, 793, 464, 435, 903, 658,\n",
              "         840, 638, 515, 894, 588, 614, 691, 606, 502, 589, 465, 808, 672, 749,\n",
              "         837, 780, 830, 529, 731, 728, 480, 643, 680, 419, 887, 514, 823, 790,\n",
              "         876, 897, 459, 914, 451, 552, 785, 777, 473, 223, 389, 652, 772, 774,\n",
              "         806, 490, 597, 233, 615, 512, 838, 836, 639, 667, 794, 702, 600, 715,\n",
              "         153, 627, 258, 977, 520, 400,  34, 395, 499, 237, 177, 463, 861, 982,\n",
              "         748, 585, 713, 559, 443, 487, 831, 999, 770, 676, 477, 257, 750, 882,\n",
              "         183, 792, 169, 929, 151, 872, 602, 358, 587, 182, 584, 518, 195, 192,\n",
              "         250, 391, 461, 265, 447, 170, 558, 259, 172, 811, 187, 224, 215, 700,\n",
              "         801, 879,   0, 813, 851, 433, 204, 439, 534, 445, 683, 251, 256, 739,\n",
              "         171, 416, 546, 173, 456, 222, 160, 741, 784, 394, 788, 669, 623, 197,\n",
              "         154, 246, 254, 450, 594, 174, 484, 764, 359, 771, 828, 202, 596, 804,\n",
              "         163, 196, 543, 646, 193, 462, 178, 593, 631, 936, 249, 211, 248, 899,\n",
              "         765,   4,  87, 845, 844, 158, 203, 217, 843, 674, 753, 112, 198, 557,\n",
              "         242, 261, 513, 679, 264, 186, 252, 677, 238, 165, 850, 859, 524, 590,\n",
              "         721, 263, 539, 641, 147, 496, 189, 179, 255, 740, 880, 424, 761, 236,\n",
              "         656, 954, 155, 681, 965, 119, 199, 981, 122, 648, 232, 421, 210, 760,\n",
              "         229, 225, 157, 235, 266, 786, 816, 262, 162, 822, 791, 782, 783, 185,\n",
              "         659, 208, 418, 579, 921, 758, 531, 313, 747, 545, 234, 881, 544,  52,\n",
              "         432, 356, 230, 871, 423, 164, 711, 862, 437, 563, 466, 227, 769, 184,\n",
              "         616, 618, 212, 542, 228, 102, 506, 905, 852, 285, 684, 904, 650, 898,\n",
              "         699, 220, 688, 896, 889, 240, 875, 642, 692, 556, 910, 519, 972, 120,\n",
              "         191, 267,  33, 522, 159, 778, 156, 209, 175, 533, 478, 176, 166, 214,\n",
              "         613, 629, 268, 470, 868, 200, 553, 763, 168, 736, 124, 226, 493, 121,\n",
              "         205, 216, 239, 511, 111, 709, 934, 118, 807,  76, 245, 827, 675, 161,\n",
              "         787,  60, 549, 541, 619, 978, 729, 206, 479, 180, 201, 213, 883, 564,\n",
              "         901, 937, 152, 583, 892, 961, 915, 738, 332, 752, 607, 420, 632, 409,\n",
              "         605, 284, 795, 188, 733, 181, 299, 243, 848, 244, 485, 664, 260, 444,\n",
              "         854, 253, 327, 742, 149, 701, 469, 190, 902,  54, 537, 504, 819, 338,\n",
              "         870, 745, 460, 818, 247, 724,  88, 436, 877, 167, 505, 317, 566, 241,\n",
              "         417, 628, 766, 194, 755, 647, 231, 719, 916, 145, 491, 219, 799, 759,\n",
              "         939, 114, 442, 918, 913, 932,  78, 535, 708,  51, 964, 482, 620, 281,\n",
              "          66, 855, 809, 412, 402, 428, 923, 554, 131, 687, 314, 725, 893, 726,\n",
              "         720, 776, 283, 422, 976, 207, 930,  91, 401,   2, 492,  80, 633, 526,\n",
              "         508, 123,  71, 413, 574, 125, 361, 446, 798, 390, 106, 438, 696, 357,\n",
              "         407, 673, 732, 528, 530, 328, 756, 329, 953, 521, 835, 789, 453, 693,\n",
              "         940, 757, 221, 846, 714, 363, 657, 458, 306, 624,  79, 966, 378, 341,\n",
              "          17, 572, 990, 273, 567, 767, 527, 853, 707, 651, 488, 956, 101, 908,\n",
              "         654,  32, 950, 942, 540, 126, 532,  61, 924, 405, 998, 454,   3, 970,\n",
              "         712, 611, 662, 626, 744, 315, 805, 665, 455, 282, 941, 653,  59, 865,\n",
              "         146, 666, 560, 330,  23, 103, 507,  69, 773, 316, 987, 718, 429, 975,\n",
              "          70, 907, 503, 974, 938, 917,  29, 148, 495, 367, 622, 298, 716, 467,\n",
              "         406, 996,  43, 279, 649, 517,  89, 538, 287, 550,  26,  58, 494, 510,\n",
              "         415,  67, 136,  63, 551, 670, 967, 723, 980, 371, 635,  65, 312, 218,\n",
              "         318, 960, 935, 582, 475, 468,  28, 754, 706, 704, 577, 270, 604, 948,\n",
              "         612,  56, 810, 703, 895, 634,  73, 303, 878, 812, 548, 310, 860, 373,\n",
              "         931, 354,   5, 110,   7, 609,  44, 569, 331, 826, 722,   6, 746, 743,\n",
              "          45,  22, 571, 334, 644,  39, 802,   8, 891, 500,  21, 486, 385,  42,\n",
              "         839, 737, 364, 962, 640, 398, 717, 833, 814, 440, 710, 481,  31, 472,\n",
              "         301, 116, 919, 372, 671, 695,  36,  57, 143, 727, 829, 943, 694, 884,\n",
              "         430,  38, 857, 637, 272, 321, 276,  64, 403, 730, 382, 448, 983, 381,\n",
              "         817, 909, 945,  48, 305, 370, 144,  96, 296, 132,  35,  62, 863, 325,\n",
              "         586, 362, 380, 280, 886,  27, 621, 108, 117, 326,  68,  18,  30, 968,\n",
              "         971, 410, 302,  47, 952,  75, 104, 322, 304, 751, 297, 768,  50, 471,\n",
              "          53, 858, 955, 928, 949, 947, 137,   1, 925, 625,  37, 995, 645, 933,\n",
              "         686, 849, 866, 113, 734, 890, 345, 598, 309, 377, 685, 525, 324, 277,\n",
              "         368, 295, 599, 311,  49,  83, 441, 781, 427,  25, 573, 969,  85, 426,\n",
              "          74, 864, 408, 319,  40, 337, 997, 951, 825, 379, 660, 779, 342, 150,\n",
              "         355, 682, 369, 127, 944, 333, 985, 856, 293, 979, 404, 323,  86,  93,\n",
              "         497,  81, 498, 292, 959,  14, 963, 958, 384, 994, 576, 832, 668, 134,\n",
              "         957, 803, 705,  82, 762, 336, 339, 365, 800, 107, 286, 912, 984, 320,\n",
              "         489, 821, 343, 307, 575, 476,  77, 873, 308, 138,  41, 346, 900, 269,\n",
              "         580,  46, 393, 661, 927, 340, 383, 386, 128, 993, 275, 348, 922, 991,\n",
              "         129, 105, 595, 347, 274, 867, 536, 366, 992, 561,  72,  95, 698, 581,\n",
              "         109, 663, 278,  90,  92,  55, 288, 335,  99, 973, 271, 392,  19, 290,\n",
              "         920,  13, 140, 592, 294, 988, 353, 989, 888, 397, 547, 690, 300, 351,\n",
              "          24, 509, 603, 374, 133, 100, 360, 376,   9, 130, 291, 135, 396, 352,\n",
              "         375, 142, 449, 425, 483, 565, 926, 847, 874,  16, 141, 289, 344, 350,\n",
              "         349, 815, 820, 388,  84, 115,  20, 139, 562, 387, 555, 946,  15,  98,\n",
              "          97, 986,  11,  12,  94,  10]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt -O imagenet_classes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE_Nui0tFSg0",
        "outputId": "5c1a5b49-f7e4-46fa-9461-46f1d1b4f0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-27 23:16:49--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-11-27 23:16:49 (14.6 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ImageNet class names\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "# Get top 5 predictions\n",
        "top5_indices = indices[0, :5].tolist()\n",
        "top5_classes = [categories[i] for i in top5_indices]\n",
        "\n",
        "print(\"Top 5 predictions:\")\n",
        "for i, class_name in enumerate(top5_classes):\n",
        "    print(f\"{i+1}: {class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8fv70SQFocU",
        "outputId": "8f321a26-468e-4f9f-bf53-6f357916466e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 predictions:\n",
            "1: jean\n",
            "2: suit\n",
            "3: sweatshirt\n",
            "4: cardigan\n",
            "5: overskirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key concepts:\n",
        "- Input size: MobileNetV2 expects 224×224 images (Xception uses 299×299)\n",
        "- Normalization: Images scaled with ImageNet mean and std\n",
        "- Batch size: Number of images processed together\n",
        "- Batch dimension: Shape (batch_size, channels, height, width) - e.g., (1, 3, 224, 224)"
      ],
      "metadata": {
        "id": "-uMGnXKJG6Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Convolutional Neural Networks\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are specialized neural networks for processing grid-like data such as images.\n"
      ],
      "metadata": {
        "id": "Q_7w1SmoG7I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Transfer Learning\n",
        "\n",
        "Transfer Learning reuses a model trained on one task (ImageNet) for a different task (clothing classification).\n",
        "\n",
        "Approach:\n",
        "\n",
        "1. Load pre-trained model (feature extractor)\n",
        "2. Remove original classification head\n",
        "3. Freeze convolutional layers\n",
        "4. Add custom layers for our task\n",
        "5. Train only the new layers\n",
        "\n",
        "### Custom Dataset Class\n",
        "\n",
        "First, create a PyTorch `Dataset` to load images:"
      ],
      "metadata": {
        "id": "BQMowmdZGmap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ClothingDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[label_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "dQZhGVNAF6Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Preprocessing"
      ],
      "metadata": {
        "id": "mMtG3gROJdCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 224\n",
        "\n",
        "# ImageNet normalization values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Simple transforms - just resize and normalize\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "5yshuVypHWiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create DataLoaders"
      ],
      "metadata": {
        "id": "TBF0p9CtJePz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = ClothingDataset(\n",
        "    data_dir='./clothing-dataset-small/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_dataset = ClothingDataset(\n",
        "    data_dir='./clothing-dataset-small/validation',\n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "FIzs-ouNI1z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Model"
      ],
      "metadata": {
        "id": "OUU6KcbJJg0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ClothingClassifierMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ClothingClassifierMobileNet, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.output_layer = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xcu-Vl-6JUPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ],
      "metadata": {
        "id": "mGaoePD-JzLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ClothingClassifierMobileNet(num_classes=10)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ddMatD_RJxMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train it:"
      ],
      "metadata": {
        "id": "2vhfMF-qKkwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over the training data\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to the specified device (GPU or CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients to prevent accumulation\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate training loss\n",
        "        running_loss += loss.item()\n",
        "        # Get predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # Update total and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average training loss and accuracy\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    # Disable gradient calculation for validation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the validation data\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the specified device (GPU or CPU)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate validation loss\n",
        "            val_loss += loss.item()\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # Update total and correct predictions\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "0jIh4Zf6KZMh",
        "outputId": "148b57ff-596e-43d1-8f20-21a8e1cb1c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  Train Loss: 1.4563, Train Acc: 0.6219\n",
            "  Val Loss: 0.8989, Val Acc: 0.7361\n",
            "Epoch 2/10\n",
            "  Train Loss: 0.7618, Train Acc: 0.7643\n",
            "  Val Loss: 0.8847, Val Acc: 0.7654\n",
            "Epoch 3/10\n",
            "  Train Loss: 0.7660, Train Acc: 0.7764\n",
            "  Val Loss: 0.9286, Val Acc: 0.7302\n",
            "Epoch 4/10\n",
            "  Train Loss: 0.6504, Train Acc: 0.8057\n",
            "  Val Loss: 1.1864, Val Acc: 0.7214\n",
            "Epoch 5/10\n",
            "  Train Loss: 0.6577, Train Acc: 0.8129\n",
            "  Val Loss: 0.8806, Val Acc: 0.7742\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.5584, Train Acc: 0.8390\n",
            "  Val Loss: 1.1510, Val Acc: 0.7361\n",
            "Epoch 7/10\n",
            "  Train Loss: 0.5853, Train Acc: 0.8442\n",
            "  Val Loss: 0.9658, Val Acc: 0.7713\n",
            "Epoch 8/10\n",
            "  Train Loss: 0.5255, Train Acc: 0.8468\n",
            "  Val Loss: 0.9106, Val Acc: 0.7830\n",
            "Epoch 9/10\n",
            "  Train Loss: 0.4877, Train Acc: 0.8644\n",
            "  Val Loss: 1.0349, Val Acc: 0.7977\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1232163874.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Iterate over the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Move data to the specified device (GPU or CPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2989167225.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's put it inside a function so it's easier for us to call it:\n"
      ],
      "metadata": {
        "id": "ZzN6A0zbNROA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "id": "J1nxOSFmKsn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Tuning the Learning Rate\n",
        "\n",
        "The learning rate controls how much to update model weights during training. It's one of the most important hyperparameters.\n",
        "\n",
        "Analogy: Reading speed\n",
        "- Too fast: Skip details, poor understanding (may not converge)\n",
        "- Too slow: Never finish the book (training takes too long)\n",
        "- Just right: Good comprehension and efficiency\n",
        "\n",
        "Experimentation approach:\n",
        "\n",
        "1. Try multiple values: `[0.0001, 0.001, 0.01, 0.1]`\n",
        "2. Train for a few epochs each\n",
        "3. Compare validation accuracy\n",
        "4. Choose the rate with best performance and smallest train/val gap\n"
      ],
      "metadata": {
        "id": "TiXqPILMXQJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.01):\n",
        "    model = ClothingClassifierMobileNet(num_classes=10)\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "ivuD5e9zXVpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test different learning rates:\n"
      ],
      "metadata": {
        "id": "R1RErfz0XX50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f'\\n=== Learning Rate: {lr} ===')\n",
        "    model, optimizer = make_model(learning_rate=lr)\n",
        "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Zbx78U_JXW7w",
        "outputId": "42389141-80c9-463b-a0da-78846ef9a59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Learning Rate: 0.0001 ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1737807639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n=== Learning Rate: {lr} ==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-131956540.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2989167225.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2319\u001b[0m                 )\n\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model Checkpointing\n",
        "\n",
        "Checkpointing saves the model during training to:\n",
        "- Keep the best performing model\n",
        "- Resume training if interrupted\n",
        "- Avoid losing progress\n",
        "\n",
        "Update the train function:"
      ],
      "metadata": {
        "id": "PCl6eYxOb5wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device):\n",
        "    best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "         # Checkpoint the model if validation accuracy improved\n",
        "        if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            checkpoint_path = f'mobilenet_v2_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f'Checkpoint saved: {checkpoint_path}')"
      ],
      "metadata": {
        "id": "XNhLht-fb6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Adding Inner Layers\n",
        "\n",
        "We can add intermediate dense layers between feature extraction and output:"
      ],
      "metadata": {
        "id": "T6eswDmSZ3Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClothingClassifierMobileNet(nn.Module):\n",
        "    def __init__(self, size_inner=100, num_classes=10):\n",
        "        super(ClothingClassifierMobileNet, self).__init__()\n",
        "\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.inner(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7k2pcX61XbZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.001, size_inner=100):\n",
        "    model = ClothingClassifierMobileNet(\n",
        "        num_classes=10,\n",
        "        size_inner=size_inner\n",
        "    )\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "x1gtzCKdZ-KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I think this it's not used.\n",
        "for size_inner in [1000, 500, 100]:\n",
        "  print(\"Size_inner = \", size_inner)\n",
        "  model, optimizer = make_model(\n",
        "      learning_rate=0.001,\n",
        "      size_inner=size_inner\n",
        "      )\n",
        "\n",
        "  train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "id": "9Mozj_ipaAsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_inner = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "model, optimizer = make_model(\n",
        "    learning_rate=learning_rate,\n",
        "    size_inner=size_inner\n",
        ")\n",
        "\n",
        "train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "id": "xyiXfnKUar8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Dropout Regularization\n",
        "\n",
        "Dropout randomly drops neurons during training to prevent overfitting.\n",
        "\n",
        "How it works:\n",
        "- Training: randomly set fraction of activations to 0\n",
        "- Inference: use all neurons (dropout disabled automatically)\n",
        "- Creates ensemble effect\n",
        "\n",
        "Benefits:\n",
        "- Prevents relying on specific features\n",
        "- Forces learning robust patterns\n",
        "- Reduces overfitting"
      ],
      "metadata": {
        "id": "a46XggtdeBjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClothingClassifierMobileNet(nn.Module):\n",
        "    def __init__(self, size_inner=100, droprate=0.2, num_classes=10):\n",
        "        super(ClothingClassifierMobileNet, self).__init__()\n",
        "\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.inner = nn.Linear(1280, size_inner)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(droprate)  # Add dropout\n",
        "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.inner(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FSsOiEzGcl6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update our function:"
      ],
      "metadata": {
        "id": "iXwNONAseF1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(\n",
        "        learning_rate=0.001,\n",
        "        size_inner=100,\n",
        "        droprate=0.2\n",
        "):\n",
        "    model = ClothingClassifierMobileNet(\n",
        "        num_classes=10,\n",
        "        size_inner=size_inner,\n",
        "        droprate=droprate\n",
        "    )\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "IlJtDl8HeFN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for droprate in [0.1, 0.2, 0.5, 0.7]:\n",
        "  print(\"Droprate = \", droprate)\n",
        "  model, optimizer = make_model(\n",
        "      learning_rate=0.001,\n",
        "      size_inner=100,\n",
        "      droprate=droprate\n",
        "  )\n",
        "\n",
        "  train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R79tH_LneLTV",
        "outputId": "fe0b8458-e7a5-4d28-c0c5-dec76068d40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Droprate =  0.1\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.3445, Train Acc: 0.5668\n",
            "  Val Loss: 0.8184, Val Acc: 0.7361\n",
            "Checkpoint saved: mobilenet_v2_01_0.736.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.7579, Train Acc: 0.7575\n",
            "  Val Loss: 0.7007, Val Acc: 0.7390\n",
            "Checkpoint saved: mobilenet_v2_02_0.739.pth\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.6233, Train Acc: 0.7937\n",
            "  Val Loss: 0.6714, Val Acc: 0.7595\n",
            "Checkpoint saved: mobilenet_v2_03_0.760.pth\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.5705, Train Acc: 0.8028\n",
            "  Val Loss: 0.5516, Val Acc: 0.8152\n",
            "Checkpoint saved: mobilenet_v2_04_0.815.pth\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.5059, Train Acc: 0.8253\n",
            "  Val Loss: 0.5907, Val Acc: 0.8035\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.4620, Train Acc: 0.8475\n",
            "  Val Loss: 0.5873, Val Acc: 0.7977\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.4477, Train Acc: 0.8468\n",
            "  Val Loss: 0.5522, Val Acc: 0.8035\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.4158, Train Acc: 0.8660\n",
            "  Val Loss: 0.5644, Val Acc: 0.8006\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.4036, Train Acc: 0.8582\n",
            "  Val Loss: 0.5289, Val Acc: 0.8299\n",
            "Checkpoint saved: mobilenet_v2_09_0.830.pth\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.3801, Train Acc: 0.8716\n",
            "  Val Loss: 0.5650, Val Acc: 0.8006\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.3593, Train Acc: 0.8713\n",
            "  Val Loss: 0.5943, Val Acc: 0.8123\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.3203, Train Acc: 0.8934\n",
            "  Val Loss: 0.5255, Val Acc: 0.8240\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.2972, Train Acc: 0.8950\n",
            "  Val Loss: 0.5344, Val Acc: 0.8182\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.2818, Train Acc: 0.8993\n",
            "  Val Loss: 0.5578, Val Acc: 0.8211\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.2831, Train Acc: 0.9009\n",
            "  Val Loss: 0.5666, Val Acc: 0.8094\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.2703, Train Acc: 0.9084\n",
            "  Val Loss: 0.5743, Val Acc: 0.8270\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.2493, Train Acc: 0.9175\n",
            "  Val Loss: 0.5904, Val Acc: 0.8094\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.2337, Train Acc: 0.9214\n",
            "  Val Loss: 0.5625, Val Acc: 0.8094\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.2245, Train Acc: 0.9201\n",
            "  Val Loss: 0.6357, Val Acc: 0.8006\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.2268, Train Acc: 0.9218\n",
            "  Val Loss: 0.5788, Val Acc: 0.8270\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.2152, Train Acc: 0.9296\n",
            "  Val Loss: 0.6650, Val Acc: 0.8006\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.1957, Train Acc: 0.9338\n",
            "  Val Loss: 0.5687, Val Acc: 0.8299\n",
            "Epoch 23/50\n",
            "  Train Loss: 0.1665, Train Acc: 0.9420\n",
            "  Val Loss: 0.6396, Val Acc: 0.8065\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.1784, Train Acc: 0.9381\n",
            "  Val Loss: 0.6020, Val Acc: 0.8182\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.1717, Train Acc: 0.9397\n",
            "  Val Loss: 0.6752, Val Acc: 0.7830\n",
            "Epoch 26/50\n",
            "  Train Loss: 0.1640, Train Acc: 0.9443\n",
            "  Val Loss: 0.6109, Val Acc: 0.8094\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.1627, Train Acc: 0.9452\n",
            "  Val Loss: 0.7586, Val Acc: 0.7713\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.1930, Train Acc: 0.9335\n",
            "  Val Loss: 0.6551, Val Acc: 0.7918\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.1720, Train Acc: 0.9413\n",
            "  Val Loss: 0.6097, Val Acc: 0.8240\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.1211, Train Acc: 0.9619\n",
            "  Val Loss: 0.6498, Val Acc: 0.8211\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.1355, Train Acc: 0.9583\n",
            "  Val Loss: 0.6551, Val Acc: 0.8123\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.1303, Train Acc: 0.9580\n",
            "  Val Loss: 0.7178, Val Acc: 0.8065\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.1554, Train Acc: 0.9534\n",
            "  Val Loss: 0.6965, Val Acc: 0.8094\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.1459, Train Acc: 0.9482\n",
            "  Val Loss: 0.6217, Val Acc: 0.8065\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.1101, Train Acc: 0.9674\n",
            "  Val Loss: 0.6437, Val Acc: 0.8006\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.1096, Train Acc: 0.9651\n",
            "  Val Loss: 0.6650, Val Acc: 0.8094\n",
            "Epoch 37/50\n",
            "  Train Loss: 0.0822, Train Acc: 0.9746\n",
            "  Val Loss: 0.7934, Val Acc: 0.7977\n",
            "Epoch 38/50\n",
            "  Train Loss: 0.1071, Train Acc: 0.9622\n",
            "  Val Loss: 0.6811, Val Acc: 0.8240\n",
            "Epoch 39/50\n",
            "  Train Loss: 0.0950, Train Acc: 0.9658\n",
            "  Val Loss: 0.6665, Val Acc: 0.8182\n",
            "Epoch 40/50\n",
            "  Train Loss: 0.0926, Train Acc: 0.9733\n",
            "  Val Loss: 0.7422, Val Acc: 0.8240\n",
            "Epoch 41/50\n",
            "  Train Loss: 0.0994, Train Acc: 0.9664\n",
            "  Val Loss: 0.7224, Val Acc: 0.8035\n",
            "Epoch 42/50\n",
            "  Train Loss: 0.0962, Train Acc: 0.9668\n",
            "  Val Loss: 0.7205, Val Acc: 0.8006\n",
            "Epoch 43/50\n",
            "  Train Loss: 0.0846, Train Acc: 0.9707\n",
            "  Val Loss: 0.8854, Val Acc: 0.7801\n",
            "Epoch 44/50\n",
            "  Train Loss: 0.0964, Train Acc: 0.9681\n",
            "  Val Loss: 0.7404, Val Acc: 0.7859\n",
            "Epoch 45/50\n",
            "  Train Loss: 0.0843, Train Acc: 0.9729\n",
            "  Val Loss: 0.7171, Val Acc: 0.8035\n",
            "Epoch 46/50\n",
            "  Train Loss: 0.1085, Train Acc: 0.9609\n",
            "  Val Loss: 0.7433, Val Acc: 0.7947\n",
            "Epoch 47/50\n",
            "  Train Loss: 0.0919, Train Acc: 0.9681\n",
            "  Val Loss: 0.7644, Val Acc: 0.7889\n",
            "Epoch 48/50\n",
            "  Train Loss: 0.0734, Train Acc: 0.9785\n",
            "  Val Loss: 0.7589, Val Acc: 0.7859\n",
            "Epoch 49/50\n",
            "  Train Loss: 0.0880, Train Acc: 0.9726\n",
            "  Val Loss: 0.7793, Val Acc: 0.7830\n",
            "Epoch 50/50\n",
            "  Train Loss: 0.0803, Train Acc: 0.9713\n",
            "  Val Loss: 0.8134, Val Acc: 0.7830\n",
            "Droprate =  0.2\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.3386, Train Acc: 0.5577\n",
            "  Val Loss: 0.8389, Val Acc: 0.7331\n",
            "Checkpoint saved: mobilenet_v2_01_0.733.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.8162, Train Acc: 0.7347\n",
            "  Val Loss: 0.7002, Val Acc: 0.7390\n",
            "Checkpoint saved: mobilenet_v2_02_0.739.pth\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.6722, Train Acc: 0.7728\n",
            "  Val Loss: 0.6314, Val Acc: 0.7889\n",
            "Checkpoint saved: mobilenet_v2_03_0.789.pth\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.6070, Train Acc: 0.7888\n",
            "  Val Loss: 0.5538, Val Acc: 0.8123\n",
            "Checkpoint saved: mobilenet_v2_04_0.812.pth\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.5322, Train Acc: 0.8168\n",
            "  Val Loss: 0.6771, Val Acc: 0.7537\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.5240, Train Acc: 0.8207\n",
            "  Val Loss: 0.5801, Val Acc: 0.8152\n",
            "Checkpoint saved: mobilenet_v2_06_0.815.pth\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.5157, Train Acc: 0.8269\n",
            "  Val Loss: 0.5725, Val Acc: 0.8006\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.4506, Train Acc: 0.8484\n",
            "  Val Loss: 0.5672, Val Acc: 0.8035\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.4313, Train Acc: 0.8514\n",
            "  Val Loss: 0.5522, Val Acc: 0.8035\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.3915, Train Acc: 0.8667\n",
            "  Val Loss: 0.5358, Val Acc: 0.8035\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.3539, Train Acc: 0.8778\n",
            "  Val Loss: 0.5525, Val Acc: 0.8182\n",
            "Checkpoint saved: mobilenet_v2_11_0.818.pth\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.3490, Train Acc: 0.8823\n",
            "  Val Loss: 0.6089, Val Acc: 0.7801\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.3575, Train Acc: 0.8752\n",
            "  Val Loss: 0.5885, Val Acc: 0.8211\n",
            "Checkpoint saved: mobilenet_v2_13_0.821.pth\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.3415, Train Acc: 0.8814\n",
            "  Val Loss: 0.6166, Val Acc: 0.7889\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.2961, Train Acc: 0.8986\n",
            "  Val Loss: 0.5912, Val Acc: 0.7977\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.3226, Train Acc: 0.8905\n",
            "  Val Loss: 0.6100, Val Acc: 0.7977\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.2772, Train Acc: 0.9065\n",
            "  Val Loss: 0.6062, Val Acc: 0.8035\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.2794, Train Acc: 0.9068\n",
            "  Val Loss: 0.5694, Val Acc: 0.8152\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.2737, Train Acc: 0.9065\n",
            "  Val Loss: 0.6294, Val Acc: 0.7771\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.2589, Train Acc: 0.9143\n",
            "  Val Loss: 0.6252, Val Acc: 0.7830\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.2454, Train Acc: 0.9107\n",
            "  Val Loss: 0.6034, Val Acc: 0.8065\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.2381, Train Acc: 0.9182\n",
            "  Val Loss: 0.5890, Val Acc: 0.8182\n",
            "Epoch 23/50\n",
            "  Train Loss: 0.2274, Train Acc: 0.9263\n",
            "  Val Loss: 0.6515, Val Acc: 0.8065\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.2006, Train Acc: 0.9309\n",
            "  Val Loss: 0.5893, Val Acc: 0.7977\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.1947, Train Acc: 0.9364\n",
            "  Val Loss: 0.5851, Val Acc: 0.8182\n",
            "Epoch 26/50\n",
            "  Train Loss: 0.2004, Train Acc: 0.9283\n",
            "  Val Loss: 0.6368, Val Acc: 0.8006\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.2007, Train Acc: 0.9270\n",
            "  Val Loss: 0.6619, Val Acc: 0.7977\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.1792, Train Acc: 0.9377\n",
            "  Val Loss: 0.6527, Val Acc: 0.8123\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.1720, Train Acc: 0.9394\n",
            "  Val Loss: 0.6732, Val Acc: 0.7771\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.1752, Train Acc: 0.9404\n",
            "  Val Loss: 0.6506, Val Acc: 0.8006\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.1742, Train Acc: 0.9390\n",
            "  Val Loss: 0.6469, Val Acc: 0.8006\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.1883, Train Acc: 0.9371\n",
            "  Val Loss: 0.6419, Val Acc: 0.8065\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.1754, Train Acc: 0.9371\n",
            "  Val Loss: 0.7136, Val Acc: 0.8123\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.1549, Train Acc: 0.9452\n",
            "  Val Loss: 0.6690, Val Acc: 0.8065\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.1500, Train Acc: 0.9475\n",
            "  Val Loss: 0.6821, Val Acc: 0.8035\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.1497, Train Acc: 0.9498\n",
            "  Val Loss: 0.6790, Val Acc: 0.7947\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2279489600.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2098178631.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Data Augmentation\n",
        "\n",
        "Data Augmentation artificially increases dataset size by applying random transformations to training images.\n",
        "\n",
        "Common transformations:\n",
        "- Rotation\n",
        "- Horizontal/vertical flipping\n",
        "- Zooming (random cropping)\n",
        "- Shifting\n",
        "- Shearing\n",
        "\n",
        "Important rules:\n",
        "- ✅ Apply ONLY to training data\n",
        "- ❌ Never augment validation/test data"
      ],
      "metadata": {
        "id": "uDUWcWLJn2ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmented Training Transforms"
      ],
      "metadata": {
        "id": "VPT5yUaMn3tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training transforms WITH augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),           # Rotate up to 10 degrees\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),  # Zoom\n",
        "    transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Validation transforms - NO augmentation, same as before\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "G6judrzBiRN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use augmentation:\n",
        "1. Small datasets\n",
        "2. Risk of overfitting\n",
        "3. Images can appear in different orientations\n",
        "\n",
        "Tips:\n",
        "- Choose augmentations that make sense for your data\n",
        "- Too much augmentation can hurt performance\n",
        "- Usually requires longer training (more epochs)\n",
        "- If no improvement after ~20 epochs, don't use it\n"
      ],
      "metadata": {
        "id": "LojLtU16oA7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Using the Trained Model\n",
        "\n",
        "### Loading a Saved Model"
      ],
      "metadata": {
        "id": "4FQPAAIeoobz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Find best checkpoint\n",
        "list_of_files = glob.glob('mobilenet_v2_*.pth')\n",
        "latest_file = max(list_of_files, key=os.path.getctime)\n",
        "print(f\"Loading model from: {latest_file}\")\n",
        "\n",
        "# Load model\n",
        "# The checkpoint 'mobilenet_v2_13_0.821.pth' was saved with size_inner=100 (from previous training)\n",
        "model = ClothingClassifierMobileNet(size_inner=100, droprate=0.2, num_classes=10)\n",
        "model.load_state_dict(torch.load(latest_file))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYMyTe1Foo_J",
        "outputId": "fc1e6d0e-b8d4-4a8f-c3c4-4923ea4db84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: mobilenet_v2_13_0.821.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClothingClassifierMobileNet(\n",
              "  (base_model): MobileNetV2(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (16): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (17): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (18): Conv2dNormActivation(\n",
              "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (classifier): Identity()\n",
              "  )\n",
              "  (global_avg_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (inner): Linear(in_features=1280, out_features=100, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (output_layer): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions"
      ],
      "metadata": {
        "id": "NQjHsaHgpDMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_image_helper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "PSpd-BUzwNXb",
        "outputId": "fe3f7992-cfc6-4bf4-f892-76be44b598f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_image_helper\n",
            "  Downloading keras_image_helper-0.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting numpy>=2.3.2 (from keras_image_helper)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=11.3.0 in /usr/local/lib/python3.12/dist-packages (from keras_image_helper) (11.3.0)\n",
            "Downloading keras_image_helper-0.0.2-py3-none-any.whl (5.4 kB)\n",
            "Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, keras_image_helper\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras_image_helper-0.0.2 numpy-2.3.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ad177191272540b8ab47f19e3dacb76c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_image_helper import create_preprocessor\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_pytorch_style(X):\n",
        "    # X: shape (1, 224, 224, 3), dtype=float32, values in [0, 255]\n",
        "    X = X / 255.0\n",
        "\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
        "\n",
        "    # Convert NHWC → NCHW (batch, height, width, channels → batch, channels, height, width)\n",
        "    X = X.transpose(0, 3, 1, 2)\n",
        "\n",
        "    # Normalize\n",
        "    X = (X - mean) / std\n",
        "\n",
        "    return X.astype(np.float32)\n",
        "\n",
        "preprocessor = create_preprocessor(preprocess_pytorch_style, target_size=(224, 224))\n",
        "\n",
        "# Predict from URL\n",
        "url = 'http://bit.ly/mlbookcamp-pants'\n",
        "X = preprocessor.from_url(url)\n",
        "X = torch.Tensor(X).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(X).cpu().numpy()[0]\n",
        "\n",
        "classes = [\n",
        "    \"dress\", \"hat\", \"longsleeve\", \"outwear\", \"pants\",\n",
        "    \"shirt\", \"shoes\", \"shorts\", \"skirt\", \"t-shirt\"\n",
        "]\n",
        "\n",
        "result = dict(zip(classes, pred.tolist()))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PZf7_tJorVG",
        "outputId": "1cbfb3dc-795c-4bd2-e4bb-3dc6411b1fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dress': 0.11260540783405304, 'hat': -7.777731895446777, 'longsleeve': -1.7832870483398438, 'outwear': -0.6925902962684631, 'pants': 4.782951831817627, 'shirt': -0.5334362387657166, 'shoes': -6.162081241607666, 'shorts': 1.1019656658172607, 'skirt': -2.7089529037475586, 't-shirt': -3.099774122238159}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Exporting to ONNX\n",
        "\n",
        "ONNX (Open Neural Network Exchange) is a format for model interoperability.\n",
        "\n",
        "Benefits:\n",
        "- Deploy on different platforms\n",
        "- Use optimized runtimes (ONNX Runtime)\n",
        "- Better inference performance\n",
        "- Language-agnostic deployment\n"
      ],
      "metadata": {
        "id": "-llmB_R-pIM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bKHzMC8sj_K",
        "outputId": "5927a2a3-b4ff-4a00-9979-602262fbcf59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.3.5)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.3.5)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.19.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.6-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n",
            "Successfully installed onnx_ir-0.1.12 onnxscript-0.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy input\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_path = \"clothing_classifier_mobilenet_v2.onnx\"\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    onnx_path,\n",
        "    verbose=True,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={\n",
        "        'input': {0: 'batch_size'},\n",
        "        'output': {0: 'batch_size'}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Model exported to {onnx_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv-ZV8pxpTVF",
        "outputId": "77477600-43a8-492f-8def-f3b5536f77f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2777746402.py:7: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `ClothingClassifierMobileNet([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ClothingClassifierMobileNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 105 of general pattern rewrite rules.\n",
            "Model exported to clothing_classifier_mobilenet_v2.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use it in the Serverless module.\n"
      ],
      "metadata": {
        "id": "n4apwMmTpebW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "## TensorFlow/Keras vs PyTorch Quick Reference\n",
        "\n",
        "| Concept | TensorFlow/Keras | PyTorch |\n",
        "|---------|------------------|---------|\n",
        "| Framework | High-level API (Keras) on TensorFlow | Low-level, explicit control |\n",
        "| Data Loading | `ImageDataGenerator` | `Dataset` + `DataLoader` |\n",
        "| Transforms | `preprocessing_function` | `transforms.Compose()` |\n",
        "| Model | Functional API or Sequential | `nn.Module` class |\n",
        "| Layers | `keras.layers.Dense()` | `nn.Linear()` |\n",
        "| Training | `model.fit()` | Manual training loop |\n",
        "| Loss | `CategoricalCrossentropy` | `CrossEntropyLoss` |\n",
        "| Optimizer | `keras.optimizers.Adam` | `optim.Adam` |\n",
        "| Saving | `.h5` or `.keras` | `.pth` or `.pt` |\n",
        "| Checkpointing | `ModelCheckpoint` callback | Manual in training loop |\n",
        "| Device | Automatic | Explicit `.to(device)` |\n",
        "\n",
        "## Key Concepts Learned\n",
        "\n",
        "1. Transfer Learning: Reuse pre-trained models for new tasks\n",
        "2. CNN Architecture: Conv layers → Pooling → Dense layers\n",
        "3. Hyperparameter Tuning: Learning rate is critical\n",
        "4. Regularization: Dropout prevents overfitting\n",
        "5. Data Augmentation: Increases effective dataset size\n",
        "6. Model Checkpointing: Save best models during training\n",
        "7. PyTorch Workflow: Dataset → DataLoader → Model → Training Loop\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "1. Start with pre-trained models (transfer learning)\n",
        "2. Freeze convolutional layers initially\n",
        "3. Use appropriate normalization (match pre-training)\n",
        "4. Experiment with one hyperparameter at a time\n",
        "5. Monitor train/val gap for overfitting\n",
        "6. Use checkpointing to save best models\n",
        "7. Augment training data only, not validation\n",
        "8. Train longer with dropout and augmentation\n",
        "9. Use GPU when available: `torch.cuda.is_available()`\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Try different pre-trained models (ResNet, EfficientNet)\n",
        "- Experiment with learning rate schedulers\n",
        "- Fine-tune the entire model (unfreeze convolutional layers)\n",
        "- Try different optimizers (SGD with momentum, AdamW)\n",
        "- Deploy the ONNX model (see [mlzoomcamp-serverless](../mlzoomcamp-serverless/))\n",
        "- Explore the original [TensorFlow/Keras version](08-deep-learning/)\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [PyTorch Documentation](https://pytorch.org/docs/)\n",
        "- [torchvision Models](https://pytorch.org/vision/stable/models.html)\n",
        "- [ML Zoomcamp Course](https://github.com/DataTalksClub/machine-learning-zoomcamp)\n",
        "- [Original Tutorial (TensorFlow/Keras)](08-deep-learning/)\n",
        "- [ONNX Documentation](https://onnx.ai/)\n",
        "\n",
        "## Credits\n",
        "\n",
        "This workshop is based on the ML Zoomcamp Deep Learning module by [Alexey Grigorev](https://github.com/alexeygrigorev), adapted to use PyTorch instead of TensorFlow/Keras.\n"
      ],
      "metadata": {
        "id": "mm1D9U9bpWSr"
      }
    }
  ]
}