{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sargent-mg/ml-zoomcamp/blob/main/08-deep-learning/notebook_w8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# Clothing Classification with PyTorch (With Hyperparameter Tuning)\n",
        "\n",
        "This notebook trains a neural network to classify 10 different types of clothing. It includes a dedicated step to automatically find the best model configuration.\n",
        "\n",
        "### Workflow:\n",
        "1.  **Data Setup:** Load images and apply augmentations.\n",
        "2.  **Model Architecture:** Define a flexible MobileNetV2 wrapper.\n",
        "3.  **Hyperparameter Tuning:** Systematically test different Learning Rates, Dropout Rates, and Layer Sizes to find the best combination.\n",
        "4.  **Final Training:** Train the best model for a longer period.\n",
        "5.  **Deployment:** Export to ONNX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_md"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ab02c1-e647-44e9-c58b-ca9acec1c32a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_md"
      },
      "source": [
        "## 2. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06426632-545e-4034-8558-0a4bf2f2a215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clothing-dataset-small'...\n",
            "remote: Enumerating objects: 3839, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (400/400), done.\u001b[K\n",
            "remote: Total 3839 (delta 9), reused 385 (delta 0), pack-reused 3439 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3839/3839), 100.58 MiB | 36.63 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_md"
      },
      "source": [
        "## 3. Dataset & Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_class"
      },
      "outputs": [],
      "source": [
        "class ClothingDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[label_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "transforms"
      },
      "outputs": [],
      "source": [
        "input_size = 224\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(input_size, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "train_dataset = ClothingDataset('./clothing-dataset-small/train', transform=train_transforms)\n",
        "val_dataset = ClothingDataset('./clothing-dataset-small/validation', transform=val_transforms)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_md"
      },
      "source": [
        "## 4. Model Architecture\n",
        "We use a class that allows us to easily change the `size_inner` and `droprate` for tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_class"
      },
      "outputs": [],
      "source": [
        "class ClothingClassifierMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, size_inner=100, droprate=0.2):\n",
        "        super(ClothingClassifierMobileNet, self).__init__()\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.inner = nn.Linear(1280, size_inner)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(droprate)\n",
        "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.inner(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utils_md"
      },
      "source": [
        "## 5. Training Utilities\n",
        "Updated `train_and_evaluate` to **return** the best validation accuracy so we can compare models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_utils"
      },
      "outputs": [],
      "source": [
        "def make_model(learning_rate=0.001, size_inner=100, droprate=0.2, num_classes=10):\n",
        "    model = ClothingClassifierMobileNet(\n",
        "        num_classes=num_classes,\n",
        "        size_inner=size_inner,\n",
        "        droprate=droprate\n",
        "    )\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    return model, optimizer\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device, save_name=None, verbose=True):\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            if save_name:\n",
        "                torch.save(model.state_dict(), save_name)\n",
        "                if verbose: print(f'  --> Saved {save_name}')\n",
        "\n",
        "    return best_val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuning_md"
      },
      "source": [
        "## 6. Hyperparameter Tuning\n",
        "\n",
        "We perform a **Grid Search** over a set of parameters. We train each combination for a few epochs (5) to see which one converges best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuning_loop",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "a5a17319-e274-4385-cf78-ad0d556a4d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Hyperparameter Tuning...\n",
            "\n",
            "Testing: LR=0.01, Size=100, Drop=0.0\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Val Accuracy: 0.7830\n",
            "Testing: LR=0.01, Size=100, Drop=0.2\n",
            "  -> Val Accuracy: 0.7361\n",
            "Testing: LR=0.01, Size=100, Drop=0.5\n",
            "  -> Val Accuracy: 0.4897\n",
            "Testing: LR=0.01, Size=256, Drop=0.0\n",
            "  -> Val Accuracy: 0.7507\n",
            "Testing: LR=0.01, Size=256, Drop=0.2\n",
            "  -> Val Accuracy: 0.7243\n",
            "Testing: LR=0.01, Size=256, Drop=0.5\n",
            "  -> Val Accuracy: 0.3783\n",
            "Testing: LR=0.001, Size=100, Drop=0.0\n",
            "  -> Val Accuracy: 0.8006\n",
            "Testing: LR=0.001, Size=100, Drop=0.2\n",
            "  -> Val Accuracy: 0.8094\n",
            "Testing: LR=0.001, Size=100, Drop=0.5\n",
            "  -> Val Accuracy: 0.7889\n",
            "Testing: LR=0.001, Size=256, Drop=0.0\n",
            "  -> Val Accuracy: 0.8094\n",
            "Testing: LR=0.001, Size=256, Drop=0.2\n",
            "  -> Val Accuracy: 0.7947\n",
            "Testing: LR=0.001, Size=256, Drop=0.5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2520939521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Train for only 5 epochs to test performance quickly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             acc = train_and_evaluate(\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-466485141.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, optimizer, train_loader, val_loader, criterion, num_epochs, device, save_name, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the search space\n",
        "learning_rates = [0.01, 0.001]\n",
        "inner_sizes = [100, 256]\n",
        "dropouts = [0.0, 0.2, 0.5]\n",
        "\n",
        "results = {}\n",
        "best_accuracy = 0.0\n",
        "best_params = {}\n",
        "\n",
        "print(\"Starting Hyperparameter Tuning...\\n\")\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for size in inner_sizes:\n",
        "        for drop in dropouts:\n",
        "            print(f\"Testing: LR={lr}, Size={size}, Drop={drop}\")\n",
        "\n",
        "            # Create model with current params\n",
        "            model, optimizer = make_model(\n",
        "                learning_rate=lr,\n",
        "                size_inner=size,\n",
        "                droprate=drop\n",
        "            )\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Train for only 5 epochs to test performance quickly\n",
        "            acc = train_and_evaluate(\n",
        "                model, optimizer,\n",
        "                train_loader, val_loader,\n",
        "                criterion,\n",
        "                num_epochs=5,\n",
        "                device=device,\n",
        "                verbose=False # Keep output clean\n",
        "            )\n",
        "\n",
        "            print(f\"  -> Val Accuracy: {acc:.4f}\")\n",
        "            results[(lr, size, drop)] = acc\n",
        "\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                best_params = {'lr': lr, 'size': size, 'drop': drop}\n",
        "\n",
        "print(\"\\n--- Tuning Complete ---\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_training_md"
      },
      "source": [
        "## 7. Final Training\n",
        "Now we take the `best_params` found above and train for a full 10 epochs to get our production model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_training"
      },
      "outputs": [],
      "source": [
        "print(f\"Training final model with: {best_params}\")\n",
        "\n",
        "final_model, final_optimizer = make_model(\n",
        "    learning_rate=best_params['lr'],\n",
        "    size_inner=best_params['size'],\n",
        "    droprate=best_params['drop']\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate(\n",
        "    final_model,\n",
        "    final_optimizer,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_name='clothing_model_tuned_best.pth'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference_md"
      },
      "source": [
        "## 8. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prediction"
      },
      "outputs": [],
      "source": [
        "!pip install keras_image_helper\n",
        "from keras_image_helper import create_preprocessor\n",
        "\n",
        "# Load the best model structure based on tuning results\n",
        "best_model = ClothingClassifierMobileNet(\n",
        "    size_inner=best_params['size'],\n",
        "    droprate=best_params['drop']\n",
        ")\n",
        "best_model.load_state_dict(torch.load('clothing_model_tuned_best.pth'))\n",
        "best_model.to(device)\n",
        "best_model.eval()\n",
        "\n",
        "def preprocess_pytorch_style(X):\n",
        "    X = X / 255.0\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
        "    X = X.transpose(0, 3, 1, 2)\n",
        "    X = (X - mean) / std\n",
        "    return X.astype(np.float32)\n",
        "\n",
        "preprocessor = create_preprocessor(preprocess_pytorch_style, target_size=(224, 224))\n",
        "url = 'http://bit.ly/mlbookcamp-pants'\n",
        "X = preprocessor.from_url(url)\n",
        "X = torch.Tensor(X).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = best_model(X).cpu().numpy()[0]\n",
        "\n",
        "classes = [\"dress\", \"hat\", \"longsleeve\", \"outwear\", \"pants\", \"shirt\", \"shoes\", \"shorts\", \"skirt\", \"t-shirt\"]\n",
        "result = dict(zip(classes, pred.tolist()))\n",
        "sorted_result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\n",
        "print(sorted_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onnx_md"
      },
      "source": [
        "## 9. Export to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export_onnx"
      },
      "outputs": [],
      "source": [
        "!pip install onnx onnxscript\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "onnx_path = \"clothing_classifier_tuned.onnx\"\n",
        "\n",
        "torch.onnx.export(\n",
        "    best_model,\n",
        "    dummy_input,\n",
        "    onnx_path,\n",
        "    verbose=False,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
        ")\n",
        "print(f\"Model exported to {onnx_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}