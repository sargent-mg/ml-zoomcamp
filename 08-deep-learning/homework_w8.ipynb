{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sargent-mg/ml-zoomcamp/blob/main/08-deep-learning/homework_w8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh2x9hm9n0ri"
      },
      "source": [
        "# ML Zoomcamp Homework 8: CNNs\n",
        "\n",
        "This notebook contains the solution for the Convolutional Neural Networks homework.\n",
        "\n",
        "### 1. Setup and Data Preparation\n",
        "\n",
        "First, we import the necessary libraries and set the seeds for reproducibility as specified in the homework."
      ],
      "id": "Dh2x9hm9n0ri"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIGPLwV7n0rj",
        "outputId": "ae802946-9853-4564-ab30-cf6ee366ee2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "\n",
        "# Reproducibility settings\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "id": "JIGPLwV7n0rj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtu_tIg6n0rj"
      },
      "source": [
        "### Download the Dataset"
      ],
      "id": "jtu_tIg6n0rj"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-SYAdGwn0rj",
        "outputId": "ece7845c-473d-4bef-d114-a903797e1f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 20:38:41--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-01T21%3A26%3A47Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-01T20%3A26%3A04Z&ske=2025-12-01T21%3A26%3A47Z&sks=b&skv=2018-11-09&sig=btyi7sLhcjgtacrWuA4WTzNQhq4ajTYaYi%2BC8xZ8Y3M%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDYyMzMyMSwibmJmIjoxNzY0NjIxNTIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.koN0NqyXIU1KsEbFbTA8rJDsjS5LpS4grg-czBUeQUU&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-01 20:38:41--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-01T21%3A26%3A47Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-01T20%3A26%3A04Z&ske=2025-12-01T21%3A26%3A47Z&sks=b&skv=2018-11-09&sig=btyi7sLhcjgtacrWuA4WTzNQhq4ajTYaYi%2BC8xZ8Y3M%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDYyMzMyMSwibmJmIjoxNzY0NjIxNTIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.koN0NqyXIU1KsEbFbTA8rJDsjS5LpS4grg-czBUeQUU&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102516572 (98M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  97.77M   177MB/s    in 0.6s    \n",
            "\n",
            "2025-12-01 20:38:42 (177 MB/s) - ‘data.zip’ saved [102516572/102516572]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
        "!unzip -q data.zip"
      ],
      "id": "K-SYAdGwn0rj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca5uE8prn0rj"
      },
      "source": [
        "### 2. Model Definition\n",
        "\n",
        "We define the Convolutional Neural Network structure as described:\n",
        "* Input: `(3, 200, 200)`\n",
        "* Conv2d: 32 filters, kernel (3,3), stride 1, padding 0, ReLU\n",
        "* MaxPool2d: (2,2)\n",
        "* Flatten\n",
        "* Linear: 64 neurons, ReLU\n",
        "* Output: 1 neuron"
      ],
      "id": "Ca5uE8prn0rj"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AiesKoPun0rj"
      },
      "outputs": [],
      "source": [
        "class HairClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HairClassifier, self).__init__()\n",
        "        # Conv Layer: 3 input channels, 32 output channels, 3x3 kernel\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Flattening\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Calculate size after Conv + Pool\n",
        "        # Input: 200x200\n",
        "        # Conv (3x3, no pad): 200 - 3 + 1 = 198\n",
        "        # Pool (2x2): 198 / 2 = 99\n",
        "        # Feature map size: 32 * 99 * 99\n",
        "        self.fc_input_size = 32 * 99 * 99\n",
        "\n",
        "        self.fc1 = nn.Linear(self.fc_input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 1) # Binary classification output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        # Note: No Sigmoid here because we will use BCEWithLogitsLoss\n",
        "        # The provided training code applies torch.sigmoid(outputs) manually for accuracy calc\n",
        "        return x"
      ],
      "id": "AiesKoPun0rj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwTU2gC2n0rj"
      },
      "source": [
        "### Question 1: Loss Function\n",
        "Since we are doing binary classification and the provided training loop applies `sigmoid` to the outputs manually (`torch.sigmoid(outputs) > 0.5`), the model should output **logits**.\n",
        "\n",
        "Therefore, the correct loss function is **`nn.BCEWithLogitsLoss()`**."
      ],
      "id": "IwTU2gC2n0rj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APbzMhFNn0rj"
      },
      "source": [
        "### Question 2: Number of Parameters"
      ],
      "id": "APbzMhFNn0rj"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV1Xt-Din0rj",
        "outputId": "4fe9c8af-7b98-4b1f-c9f2-e6b833bc53f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 20073473\n"
          ]
        }
      ],
      "source": [
        "model = HairClassifier().to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")"
      ],
      "id": "GV1Xt-Din0rj"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "79c09d25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c09d25",
        "outputId": "ffd1d700-97b8-41f0-f288-df76cacdc61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 198, 198]             896\n",
            "              ReLU-2         [-1, 32, 198, 198]               0\n",
            "         MaxPool2d-3           [-1, 32, 99, 99]               0\n",
            "           Flatten-4               [-1, 313632]               0\n",
            "            Linear-5                   [-1, 64]      20,072,512\n",
            "              ReLU-6                   [-1, 64]               0\n",
            "            Linear-7                    [-1, 1]              65\n",
            "================================================================\n",
            "Total params: 20,073,473\n",
            "Trainable params: 20,073,473\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 23.93\n",
            "Params size (MB): 76.57\n",
            "Estimated Total Size (MB): 100.96\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "%pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxreEQF4n0rk"
      },
      "source": [
        "### 3. Training Preparation\n",
        "\n",
        "We define the transforms and create the DataLoaders."
      ],
      "id": "kxreEQF4n0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B9XR0bVmn0rk"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Dataset Setup\n",
        "train_dataset = ImageFolder('./data/train', transform=train_transforms)\n",
        "validation_dataset = ImageFolder('./data/test', transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "# Optimizer and Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "id": "B9XR0bVmn0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHPrBe5jn0rk"
      },
      "source": [
        "### 4. Training Loop (First Run)\n",
        "\n",
        "Running for 10 epochs as requested."
      ],
      "id": "UHPrBe5jn0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avwwiVm5n0rk",
        "outputId": "0ee3fc5c-0b6c-48d9-a5b4-52a01091781d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6665, Acc: 0.6112, Val Loss: 0.6511, Val Acc: 0.6617\n",
            "Epoch 2/10, Loss: 0.5702, Acc: 0.6787, Val Loss: 0.6332, Val Acc: 0.6318\n",
            "Epoch 3/10, Loss: 0.5207, Acc: 0.7350, Val Loss: 0.6143, Val Acc: 0.6766\n",
            "Epoch 4/10, Loss: 0.4773, Acc: 0.7600, Val Loss: 0.6049, Val Acc: 0.6617\n",
            "Epoch 5/10, Loss: 0.4606, Acc: 0.7550, Val Loss: 0.7307, Val Acc: 0.5672\n",
            "Epoch 6/10, Loss: 0.3954, Acc: 0.8275, Val Loss: 0.6412, Val Acc: 0.6866\n",
            "Epoch 7/10, Loss: 0.2844, Acc: 0.8838, Val Loss: 0.8307, Val Acc: 0.6816\n",
            "Epoch 8/10, Loss: 0.2885, Acc: 0.8788, Val Loss: 0.7052, Val Acc: 0.7114\n",
            "Epoch 9/10, Loss: 0.1882, Acc: 0.9313, Val Loss: 0.9275, Val Acc: 0.6866\n",
            "Epoch 10/10, Loss: 0.2585, Acc: 0.8912, Val Loss: 0.8158, Val Acc: 0.6915\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
      ],
      "id": "avwwiVm5n0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2LmRNben0rk"
      },
      "source": [
        "### Question 3: Median Training Accuracy"
      ],
      "id": "T2LmRNben0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfZKLdFPn0rk",
        "outputId": "857922b1-6939-47da-88bf-a4b8b9a49872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median Training Accuracy: 0.7937\n"
          ]
        }
      ],
      "source": [
        "median_acc = np.median(history['acc'])\n",
        "print(f\"Median Training Accuracy: {median_acc:.4f}\")"
      ],
      "id": "hfZKLdFPn0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRS9qHpjn0rk"
      },
      "source": [
        "### Question 4: Standard Deviation of Training Loss"
      ],
      "id": "PRS9qHpjn0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-krusQLXn0rk",
        "outputId": "915194d9-a597-4cba-d7ae-dba5cb5e05d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std Training Loss: 0.1462\n"
          ]
        }
      ],
      "source": [
        "std_loss = np.std(history['loss'])\n",
        "print(f\"Std Training Loss: {std_loss:.4f}\")"
      ],
      "id": "-krusQLXn0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q_sugBCn0rk"
      },
      "source": [
        "### 5. Data Augmentation\n",
        "\n",
        "We now add the requested augmentations to the training set and continue training the **same** model for 10 more epochs."
      ],
      "id": "0q_sugBCn0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpjkUAdFn0rk",
        "outputId": "f36d3126-5a92-4e28-f0fb-7ce7b9b90092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing training with augmentations...\n",
            "Epoch 11/20, Loss: 0.6307, Acc: 0.6600, Val Loss: 0.5963, Val Acc: 0.7114\n",
            "Epoch 12/20, Loss: 0.5801, Acc: 0.6750, Val Loss: 0.5968, Val Acc: 0.7214\n",
            "Epoch 13/20, Loss: 0.5374, Acc: 0.7175, Val Loss: 0.5870, Val Acc: 0.7015\n",
            "Epoch 14/20, Loss: 0.5502, Acc: 0.7125, Val Loss: 0.5695, Val Acc: 0.7264\n",
            "Epoch 15/20, Loss: 0.5250, Acc: 0.7412, Val Loss: 0.6758, Val Acc: 0.6816\n",
            "Epoch 16/20, Loss: 0.5141, Acc: 0.7612, Val Loss: 0.5764, Val Acc: 0.7313\n",
            "Epoch 17/20, Loss: 0.5217, Acc: 0.7362, Val Loss: 0.5756, Val Acc: 0.6866\n",
            "Epoch 18/20, Loss: 0.4888, Acc: 0.7588, Val Loss: 0.5724, Val Acc: 0.7214\n",
            "Epoch 19/20, Loss: 0.4989, Acc: 0.7475, Val Loss: 0.5452, Val Acc: 0.7313\n",
            "Epoch 20/20, Loss: 0.4663, Acc: 0.7688, Val Loss: 0.5619, Val Acc: 0.7164\n"
          ]
        }
      ],
      "source": [
        "aug_train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(50),\n",
        "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((200, 200)), # Resize is needed after crop to ensure consistency if crop varies\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Update the training dataset with new transforms\n",
        "train_dataset_aug = ImageFolder('./data/train', transform=aug_train_transforms)\n",
        "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True)\n",
        "\n",
        "print(\"Continuing training with augmentations...\")\n",
        "\n",
        "# We continue using 'history' to append new results\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    # Use the new augmented loader\n",
        "    for images, labels in train_loader_aug:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset_aug)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+11}/{num_epochs*2}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
      ],
      "id": "lpjkUAdFn0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn39vfBtn0rk"
      },
      "source": [
        "### Question 5: Mean Test Loss (Augmented)\n",
        "Calculate mean of test loss for all epochs trained with augmentations (epochs 11-20)."
      ],
      "id": "Sn39vfBtn0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8gPJW8fn0rk",
        "outputId": "b9c66178-4446-4b99-bec0-db5045dc7307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Val Loss (Augmented): 0.5857\n"
          ]
        }
      ],
      "source": [
        "# The history list now contains 20 items. Indices 10 to 19 correspond to the augmented training.\n",
        "aug_val_losses = history['val_loss'][10:]\n",
        "mean_aug_val_loss = np.mean(aug_val_losses)\n",
        "print(f\"Mean Val Loss (Augmented): {mean_aug_val_loss:.4f}\")"
      ],
      "id": "F8gPJW8fn0rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQHqt7k1n0rk"
      },
      "source": [
        "### Question 6: Average Test Accuracy (Last 5 Epochs)\n",
        "Calculate average test accuracy for the last 5 epochs (epochs 16-20)."
      ],
      "id": "cQHqt7k1n0rk"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KzzLLUOn0rl",
        "outputId": "20da4f04-3520-40a1-9950-0b1bc7743894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Val Acc (Last 5): 0.7174\n"
          ]
        }
      ],
      "source": [
        "last5_val_acc = history['val_acc'][-5:]\n",
        "avg_last5_val_acc = np.mean(last5_val_acc)\n",
        "print(f\"Avg Val Acc (Last 5): {avg_last5_val_acc:.4f}\")"
      ],
      "id": "-KzzLLUOn0rl"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}