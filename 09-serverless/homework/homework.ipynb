{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedf4b10",
   "metadata": {},
   "source": [
    "# Homework.\n",
    "\n",
    "In this homework, we'll deploy the Straight vs Curly Hair Type model we trained in the previous homework.\n",
    "\n",
    "Download the model files from here:\n",
    "\n",
    "- https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\n",
    "- https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d700ad",
   "metadata": {},
   "source": [
    "### Imports and setup.\n",
    "Run this cell first to install dependencies (if needed) and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27aa3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: onnx in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.23.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/python/3.12.1/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/python/3.12.1/lib/python3.12/site-packages (from onnxruntime) (25.9.23)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from onnxruntime) (1.13.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.7.9)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pillow onnx onnxruntime requests\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d0648",
   "metadata": {},
   "source": [
    "### Constants and Configuration\n",
    "Define the URLs and filenames used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce06c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs\n",
    "MODEL_URL = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx\"\n",
    "WEIGHTS_URL = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\"\n",
    "IMAGE_URL = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "\n",
    "# Local Paths\n",
    "MODEL_PATH = os.path.join('models', 'hair_classifier_v1.onnx')\n",
    "WEIGHTS_PATH = os.path.join('models', 'hair_classifier_v1.onnx.data') # Must be in same folder as model\n",
    "IMAGE_PATH = os.path.join('data', 'image.jpeg')\n",
    "\n",
    "# Target size from Previous Homework\n",
    "TARGET_SIZE = (200, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e006bc",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "Functions to download files, process images, and prepare the input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8edfd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f\"Downloading to {save_path}...\")\n",
    "        request.urlretrieve(url, save_path)\n",
    "    else:\n",
    "        print(f\"{save_path} already exists.\")\n",
    "\n",
    "def prepare_image(img_path, target_size):\n",
    "    img = Image.open(img_path)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_input(img):\n",
    "    # Load as float32\n",
    "    x = np.array(img, dtype='float32')\n",
    "    x /= 255.0\n",
    "    \n",
    "    # Define mean and std specifically as float32 to avoid upcasting to double\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "    \n",
    "    x = (x - mean) / std\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    # Final safety cast to ensure it is strictly float32\n",
    "    return x.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef464152",
   "metadata": {},
   "source": [
    "## Question 1 (Output Node Name)\n",
    "Downloads the model and inspects the graph to find the output node name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa29a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/hair_classifier_v1.onnx already exists.\n",
      "models/hair_classifier_v1.onnx.data already exists.\n",
      "\n",
      "--- Question 1 ---\n",
      "Output node name: output\n"
     ]
    }
   ],
   "source": [
    "# 1. Download Model and Weights\n",
    "download_file(MODEL_URL, MODEL_PATH)\n",
    "download_file(WEIGHTS_URL, WEIGHTS_PATH)\n",
    "\n",
    "# 2. Question 1: Load model and get output name\n",
    "model = onnx.load(MODEL_PATH)\n",
    "output_name = model.graph.output[0].name\n",
    "\n",
    "print(f\"\\n--- Question 1 ---\")\n",
    "print(f\"Output node name: {output_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab6438",
   "metadata": {},
   "source": [
    "## Prepare Image & Question 2, 3\n",
    "Downloads the image and processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57ae7922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/image.jpeg already exists.\n",
      "\n",
      "--- Question 2 ---\n",
      "Target size used: (200, 200)\n",
      "\n",
      "--- Question 3 ---\n",
      "Value in first pixel (R channel): -1.073\n"
     ]
    }
   ],
   "source": [
    "# 1. Download Image\n",
    "download_file(IMAGE_URL, IMAGE_PATH)\n",
    "\n",
    "# 2. Process Image\n",
    "img_prepared = prepare_image(IMAGE_PATH, TARGET_SIZE)\n",
    "X_input = preprocess_input(img_prepared)\n",
    "\n",
    "# 3. Question 3: Get first pixel of R channel\n",
    "r_pixel_value = X_input[0, 0, 0, 0]\n",
    "\n",
    "print(f\"\\n--- Question 2 ---\")\n",
    "print(f\"Target size used: {TARGET_SIZE}\")\n",
    "\n",
    "print(f\"\\n--- Question 3 ---\")\n",
    "print(f\"Value in first pixel (R channel): {r_pixel_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e92032",
   "metadata": {},
   "source": [
    "## Question 4.\n",
    "Runs the model using the files in the model/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe08025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 4 ---\n",
      "Model output: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize Session using the organized path\n",
    "session = ort.InferenceSession(MODEL_PATH)\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "outputs = session.run([output_name], {input_name: X_input})\n",
    "prediction = outputs[0][0][0]\n",
    "\n",
    "print(f\"\\n--- Question 4 ---\")\n",
    "print(f\"Model output: {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad939e8",
   "metadata": {},
   "source": [
    "## Create the Lambda Function Code\n",
    "Run this cell to create the lambda_function.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5f83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_function.py\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "import os\n",
    "\n",
    "# Configuration matching the internal docker model\n",
    "MODEL_FILE = \"hair_classifier_empty.onnx\"\n",
    "TARGET_SIZE = (200, 200)\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_input(img):\n",
    "    x = np.array(img, dtype='float32')\n",
    "    x /= 255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "    x = (x - mean) / std\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x.astype('float32')\n",
    "\n",
    "# Global session to load model only once (standard Lambda practice)\n",
    "session = None\n",
    "\n",
    "def init_session():\n",
    "    global session\n",
    "    if session is None:\n",
    "        # Check if the model exists in the container\n",
    "        if not os.path.exists(MODEL_FILE):\n",
    "             raise FileNotFoundError(f\"Model file {MODEL_FILE} not found. Are you running inside the correct Docker container?\")\n",
    "        session = ort.InferenceSession(MODEL_FILE)\n",
    "\n",
    "def predict(url):\n",
    "    init_session()\n",
    "    \n",
    "    # 1. Download and Process\n",
    "    img = download_image(url)\n",
    "    img_prepared = prepare_image(img, TARGET_SIZE)\n",
    "    X = preprocess_input(img_prepared)\n",
    "    \n",
    "    # 2. Inference\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    \n",
    "    result = session.run([output_name], {input_name: X})\n",
    "    return float(result[0][0][0])\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    url = event['url']\n",
    "    result = predict(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896262d5",
   "metadata": {},
   "source": [
    "### Create the Dockerfile\n",
    "Run this cell to create the Dockerfile that defines the container environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b393ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM agrigorev/model-2025-hairstyle:v1\n",
    "\n",
    "# Install required libraries\n",
    "RUN pip install numpy onnxruntime pillow\n",
    "\n",
    "# Copy our lambda function code into the container\n",
    "COPY lambda_function.py .\n",
    "\n",
    "# Set the CMD to your handler\n",
    "CMD [ \"lambda_function.lambda_handler\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc0d64",
   "metadata": {},
   "source": [
    "## Question 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb583fd2",
   "metadata": {},
   "source": [
    "### Test Script.\n",
    "Docker cointainer must be running.\n",
    "```\n",
    "# 1. Build your custom image\n",
    "docker build -t homework-hair .\n",
    "\n",
    "# 2. Run the container (mapping port 8080)\n",
    "docker run -it --rm -p 8080:8080 homework-hair\n",
    "```\n",
    "\n",
    "The cell will create 'test.py', then you can run it in the terminal as follows:\n",
    "\n",
    "```\n",
    "python test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9464d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:8080/2015-03-31/functions/function/invocations\"\n",
    "data = {\"url\": \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=data)\n",
    "    print(\"Response status:\", response.status_code)\n",
    "    print(\"Response text:\", response.text)\n",
    "    print(f\"\\n--- Question 6 Answer ---\")\n",
    "    print(f\"Model output: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(\"Error: Could not connect to Docker. Make sure the container is running in your terminal!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38e5fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status: 200\n",
      "Response text: -0.10220836102962494\n",
      "\n",
      "--- Question 6 Answer ---\n",
      "Model output: -0.10220836102962494\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
